\chapter{Testbed Design}
\label{apx:testbed}

In this appendix, we provide the design details of our testbed that enables us to evaluate Prism on up to 1000 EC2 virtual machines. The testbed consists of a script written in 1000 lines of \texttt{Bash} that manages the EC2 cluster, and a tool written in 1200 lines of \texttt{Golang} that collects experimental data.

\section{Working with an EC2 Cluster}

The testbed runs on Amazon EC2's \texttt{c5d.4xlarge} instances. This type of instance has 16 vCPUs, 16 GB of RAM, 400 GB of NVMe SSD, and a 10 Gbps network interface. Before starting an experiment, our Bash script calls the API of AWS to start the required instances. We noticed that sometimes the AWS datacenter (US East, Ohio) may run out of capacity and was unable to provide the instances. The situation usually resolves within a few minutes as the datacenter auto-provisions more instances of the type, and our script is written to handle this issue.

After the instances are started, the script queries the IP addresses of the instances through AWS API and writes to the local SSH config file to enable pubkey-authenticated login. It then generates a payload for each instance, including the binary of the Prism client and the full command that starts the client. To deploy the payload, instead of sending to individual servers through \texttt{scp}, it first uploads the payload to AWS S3 and controls each VM to download the payload from S3, avoiding sending the large binary files through the internet multiple times. It then mounts the NVMe storage on each VM, and configures the network bandwidth limiter and sets up an artificial delay to mimic the real internet. Specifically, we limit the total egress and ingress bandwidth respectively. While it is straightforward to shape the egress traffic by setting up \texttt{qdisc}, Linux does not allow traffic shaping of ingress traffic directly. As a solution, we forward all ingress traffic to an \texttt{ifb} device, and set up \texttt{qdisc} on this device. Finally, we tune the TCP send and receive buffer sizes to make sure the bandwidth is fully utilized.

In addition to provisioning EC2 VMs, the Bash script also has a few features to help us debug the testbed. Specifically, we found that being able to easily profile the program using Flamegraph is very useful for performance debugging and encourages us to fine-tune the program, especially since our local development machine alone does not have the hardware resource to achieve a high transaction throughput and forbids us to reproduce performance issues locally. Also, we added a function to remotely check the correctness of the system, e.g. whether all instances reach consensus and agree on the same UTXO set. This feature allowed us to capture many obscure race conditions.

\section{Monitoring the performance}

To monitor the experiment, we wrote a tool in Golang that communicates with the HTTP API of our Prism client. It periodically queries the clients and displays the following performance metrics: generated transactions, confirmed transactions, deconfirmed transactions, local network queue length, mined blocks, local block propagation delay, received blocks, confirmation latency, and forking. It also stores the time-series data in a local round-robin database and plots the data in real-time. We found that having the ability to monitor many metrics of the system is very useful for debugging, especially when the cluster involves hundreds of VMs. For example, we discovered a performance bug due to bad usage of Mutex when we noticed unusual spikes of network queuing latency. Also, collecting time-series data in real-time allows us to display the results in a Grafana dashboard during presentations and demos.
